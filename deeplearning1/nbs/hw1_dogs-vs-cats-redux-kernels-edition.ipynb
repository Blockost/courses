{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs vs cats "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will serve as the reference script for solving the Kaggle's [Dogs vs Cats](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition) classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get dataset from Kaggle and structure it the way the VGG16 model can work on\n",
    "2. Train the model (training set) and valid it (validation set)\n",
    "3. For each image in the test set (125000) images, predict the class, either \"dog\" or \"cat\"\n",
    "4. Write the probabilities into a .csv file \n",
    "5. Submit it to the Kaggle competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating validation set and sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import modules\n",
    "import os\n",
    "from shutil import copyfile\n",
    "\n",
    "from utils import *\n",
    "from vgg16 import Vgg16\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Where are we ?\n",
    "% pwd\n",
    "\n",
    "data_dir = 'data/dogs-vs-cats-redux-kernels-edition/'\n",
    "sample_dir = 'data/dogs-vs-cats-redux-kernels-edition/sample/'\n",
    "\n",
    "test_dir = \"data/dogs-vs-cats-redux-kernels-edition/test/\"\n",
    "result_dir = \"./\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create valid directory and subdirectories\n",
    "% mkdir -p $data_dir/valid/dogs\n",
    "%mkdir -p $data_dir/valid/cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Move 2000 images from train to valid (1000 dogs and 1000 cats)\n",
    "\n",
    "g = glob(data_dir + 'train/dogs/*.jpg')\n",
    "imgs = np.random.permutation(g)\n",
    "for i in range(1000):\n",
    "    filename = imgs[i].split('/')[-1:][0]\n",
    "    os.rename(imgs[i], data_dir + 'valid/' + filename)\n",
    "    \n",
    "\n",
    "g = glob(data_dir + 'train/cats/*.jpg')\n",
    "imgs = np.random.permutation(g)\n",
    "for i in range(1000):\n",
    "    filename = imgs[i].split('/')[-1:][0]\n",
    "    os.rename(imgs[i], data_dir + 'valid/' + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create sample directory and subdirectories\n",
    "% mkdir -p $data_dir/sample/train\n",
    "% mkdir -p $data_dir/sample/valid\n",
    "\n",
    "% mkdir -p $data_dir/sample/train/dogs\n",
    "% mkdir -p $data_dir/sample/train/cats\n",
    "\n",
    "% mkdir -p $data_dir/sample/valid/dogs\n",
    "% mkdir -p $data_dir/sample/valid/cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy 200 images to sample set (100 dogs and 100 cats)\n",
    "g = glob(data_dir + 'train/dogs/*.jpg')\n",
    "imgs = np.random.permutation(g)\n",
    "for i in range(100):\n",
    "    filename = imgs[i].split('/')[-1:][0]\n",
    "    copyfile(imgs[i], data_dir + 'sample/train/' + filename)\n",
    "    \n",
    "\n",
    "g = glob(data_dir + 'train/cats/*.jpg')\n",
    "imgs = np.random.permutation(g)\n",
    "for i in range(100):\n",
    "    filename = imgs[i].split('/')[-1:][0]\n",
    "    copyfile(imgs[i], data_dir + 'sample/train/' + filename)\n",
    "    \n",
    "    \n",
    "# Move 50 images to valid sample set (25 dogs and 25 cats)\n",
    "g = glob(data_dir + 'sample/train/dog*.jpg')\n",
    "imgs = np.random.permutation(g)\n",
    "for i in range(1000):\n",
    "    filename = imgs[i].split('/')[-1:][0]\n",
    "    os.rename(imgs[i], data_dir + 'sample/valid/dogs/' + filename)\n",
    "    \n",
    "g = glob(data_dir + 'sample/train/cat*.jpg')\n",
    "imgs = np.random.permutation(g)\n",
    "for i in range(1000):\n",
    "    filename = imgs[i].split('/')[-1:][0]\n",
    "    os.rename(imgs[i], data_dir + 'sample/valid/cats/' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat 'data/dogs-vs-cats-redux-kernels-edition//valid/dog*.jpg': No such file or directory\n",
      "mv: cannot stat 'data/dogs-vs-cats-redux-kernels-edition//valid/cat*.jpg': No such file or directory\n",
      "mv: cannot stat 'data/dogs-vs-cats-redux-kernels-edition//sample/train/dog*.jpg': No such file or directory\n",
      "mv: cannot stat 'data/dogs-vs-cats-redux-kernels-edition//sample/train/cat*.jpg': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Move images to their respective folder\n",
    "\n",
    "% mv $data_dir/valid/dog*.jpg $data_dir/valid/dogs/\n",
    "% mv $data_dir/valid/cat*.jpg $data_dir/valid/cats/\n",
    "\n",
    "% mv $data_dir/sample/train/dog*.jpg $data_dir/sample/train/dogs/\n",
    "% mv $data_dir/sample/train/cat*.jpg $data_dir/sample/train/cats/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce GTX 770 (CNMeM is disabled, cuDNN 5103)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "#import modules\n",
    "\n",
    "from utils import *\n",
    "from vgg16 import Vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Instantiate our pre-trained model\n",
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define training constant\n",
    "batch_size=16\n",
    "n_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Load data as batches, i.e a bunch of data grouped together\n",
    "batches = get_batches(data_dir+'train/', batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#Define validation batches as well\n",
    "valid_batches = vgg.get_batches(data_dir+\"valid/\", batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fine-tune the model\n",
    "vgg.finetune(batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "23000/23000 [==============================] - 1018s - loss: 0.1144 - acc: 0.9913 - val_loss: 3.3654 - val_acc: 0.7180\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'result_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-96274efe0ceb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mfilename_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}dogs_cats_redux_w{}.h5'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mvgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'result_dir' is not defined"
     ]
    }
   ],
   "source": [
    "# It may be important to save model's weights after each epochs\n",
    "for i in xrange(n_epochs):\n",
    "    \n",
    "    vgg.fit(batches, valid_batches)\n",
    "    \n",
    "    # Save\n",
    "    filename_weights = '{}dogs_cats_redux_w{}.h5'.format(result_dir, i + 1)\n",
    "    vgg.model.save_weights(filename_weights)\n",
    "    \n",
    "    # Log info\n",
    "    print('Epoch {} done. Weights saved under {}'.format(i + 1, filename_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches, preds = vgg.test(test_dir, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.0000e+00,   1.3986e-09],\n",
       "       [  1.0000e+00,   0.0000e+00],\n",
       "       [  1.0000e+00,   7.1887e-43],\n",
       "       [  9.9974e-01,   2.6366e-04],\n",
       "       [  8.9913e-02,   9.1009e-01],\n",
       "       [  1.0000e+00,   0.0000e+00],\n",
       "       [  1.0000e+00,   0.0000e+00],\n",
       "       [  7.0919e-06,   9.9999e-01],\n",
       "       [  1.0000e+00,   3.2951e-14],\n",
       "       [  1.0000e+00,   0.0000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Grab the dog prediction column (since Kaggle wants the probability that an image is a dog)\n",
    "isdog = preds[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unknown/1.jpg',\n",
       " 'unknown/10.jpg',\n",
       " 'unknown/100.jpg',\n",
       " 'unknown/1000.jpg',\n",
       " 'unknown/10000.jpg']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batches.filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Predictions: [  1.3986e-09   0.0000e+00   7.1887e-43   2.6366e-04   9.1009e-01]\n",
      "Mid Predictions: [ 0.5205  0.4852  0.4056  0.4245  0.4385  0.5566  0.4206  0.5939  0.5188  0.4197  0.5089  0.5047\n",
      "  0.4767  0.5491  0.4884  0.4264  0.5461  0.5655  0.4074  0.587   0.5759  0.5075  0.5979  0.452\n",
      "  0.5117  0.598   0.5792  0.4722  0.5766  0.5097  0.4302  0.4836  0.4836  0.547   0.4466  0.477\n",
      "  0.4649  0.432   0.4871  0.4541  0.5845  0.5711  0.4024  0.5439  0.4091  0.5609  0.4618  0.4489\n",
      "  0.5803  0.4566  0.4851  0.4216  0.4964  0.5072  0.5727  0.5312  0.5549  0.5294  0.4972  0.4088\n",
      "  0.4562  0.4841  0.502   0.4466  0.5769  0.5855  0.4891  0.5705  0.4378  0.5635  0.4246  0.4317\n",
      "  0.4096  0.5204  0.5083  0.4744  0.4603  0.453   0.5787  0.4551  0.5868  0.5823  0.4977  0.5864\n",
      "  0.479   0.5885  0.4875  0.5889  0.5318  0.5818  0.4026  0.5087  0.5736  0.4172  0.4435]\n",
      "Edge Predictions: [ 0.  0.  0. ...,  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print \"Raw Predictions: \" + str(isdog[:5])\n",
    "print \"Mid Predictions: \" + str(isdog[(isdog < .6) & (isdog > .4)])\n",
    "print \"Edge Predictions: \" + str(isdog[(isdog == 1) | (isdog == 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'isdog' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-81a678a2aeb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Limit the probabilities between 0.05 and 0.95 (log-loss dropped from 6.92 to 0.89 !!)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0misdog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misdog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'isdog' is not defined"
     ]
    }
   ],
   "source": [
    "# Limit the probabilities between 0.05 and 0.95 (log-loss dropped from 6.92 to 0.89 !!)\n",
    "isdog = isdog.clip(min=0.05, max=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 4. Export predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grab image IDs from filenames\n",
    "filenames = test_batches.filenames\n",
    "ids = np.array([int(f[8:f.find('.')]) for f in filenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.0000e+00,   5.0000e-02],\n",
       "       [  1.0000e+01,   5.0000e-02],\n",
       "       [  1.0000e+02,   5.0000e-02],\n",
       "       [  1.0000e+03,   5.0000e-02],\n",
       "       [  1.0000e+04,   9.1009e-01]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm = np.stack([ids,isdog], axis=1)\n",
    "subm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save to csv -- Numpy is *really* powerful\n",
    "np.savetxt('kaggle_submission.csv', subm, fmt='%d,%.5f', header='id,label', comments='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
