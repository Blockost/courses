{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from theano.sandbox import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM\n",
    "from keras.layers import TimeDistributed, Activation\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from numpy.random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters in text: 600901\n"
     ]
    }
   ],
   "source": [
    "full_text = open('data/nietzsche.txt').read().lower()\n",
    "print('Number of characters in text: {}'.format(len(full_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preface\n",
      "\n",
      "\n",
      "supposing that truth is a woman--what then? is there not ground\n",
      "for suspecting that all philosophers, in so far as they have been\n",
      "dogmatists, have failed to understand women--that the terrible\n",
      "seriousness and clumsy importunity with which they have usually paid\n",
      "their addresses to truth, have been unskilled and unseemly methods for\n",
      "winning a woman? certainly she has never allowed herself to be won; and\n",
      "at present every kind of dogma stands with sad and discouraged mien--if,\n",
      "indeed, it stands at all! for there are scoffers who maintain that it\n",
      "has fallen, that all dogma lies on the ground--nay more, that it is at\n",
      "its last gasp. but to speak seriously, there are good grounds for hoping\n",
      "that all dogmatizing in philosophy, whatever solemn, whatever conclusive\n",
      "and decided airs it has assumed, may have been only a noble puerilism\n",
      "and tyronism; and probably the time is at hand when it will be once\n",
      "and again understood what has actually sufficed for the basis of such\n",
      "imposing and abso\n"
     ]
    }
   ],
   "source": [
    "# Print 1000 first characters from the text\n",
    "print(full_text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the full text is stored in a variable, we need to create the text's vocabulary, i.e every unique characters (alphabetical, punctation and system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: \u0000\n",
      " !\"'(),-.0123456789:;=?[]_abcdefghijklmnopqrstuvwxyz������\n",
      "Size of vocabulary: 60\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(list(set(full_text)))\n",
    "vocab.insert(0, '\\0') # Add end of string in vocab\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print('Vocabulary: {}'.format(''.join(vocab)))\n",
    "print('Size of vocabulary: {}'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionnary mapping every char to its index in the vocabulary. We need it to transform the text into a array of index instead of pure characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[43, 45, 32, 33, 28, 30, 32, 1, 1, 1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_index = dict((c, i) for i, c in enumerate(vocab))\n",
    "text_as_index = [char_to_index[c] for c in full_text]\n",
    "text_as_index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600901"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_as_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final goal of our model will be to predict the next 40 characters after a sequence of 40 chars. Sequence length is totally arbitrary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences of 40 chars in text: 600860\n"
     ]
    }
   ],
   "source": [
    "# We arbitrary define a \"sentence\" as a sequence of 40 chars\n",
    "length = 40\n",
    "sentences = []\n",
    "next_chars = []\n",
    "# For each sequence of 40 chars, define the next_char (our target) to be the next one\n",
    "for i in range(len(text_as_index) - length - 1):\n",
    "    sentences.append(text_as_index[i : i+length])\n",
    "    next_chars.append(text_as_index[i+1 : i+length+1])\n",
    "    \n",
    "print('Number of sequences of 40 chars in text: {}'.format(len(sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600860, 40)\n",
      "(600860, 40)\n"
     ]
    }
   ],
   "source": [
    "sentences = np.array([np.array(sentence) for sentence in sentences])\n",
    "next_chars = np.array([np.array(next_char) for next_char in next_chars])\n",
    "\n",
    "print(sentences.shape)\n",
    "print(next_chars.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([43, 45, 32, 33, 28, 30, 32,  1,  1,  1, 46, 48, 43, 43, 42, 46, 36,\n",
       "       41, 34,  2, 47, 35, 28, 47,  2, 47, 45, 48, 47, 35,  2, 36, 46,  2,\n",
       "       28,  2, 50, 42, 40, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45, 32, 33, 28, 30, 32,  1,  1,  1, 46, 48, 43, 43, 42, 46, 36, 41,\n",
       "       34,  2, 47, 35, 28, 47,  2, 47, 45, 48, 47, 35,  2, 36, 46,  2, 28,\n",
       "        2, 50, 42, 40, 28, 41])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_chars[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 24 # ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    \n",
    "    Embedding(vocab_size, n_fac, input_length=length),\n",
    "    LSTM(512, input_dim=n_fac,return_sequences=True, dropout_U=0.2, dropout_W=0.2, consume_less='gpu'),\n",
    "    Dropout(0.2),\n",
    "    LSTM(512, return_sequences=True, dropout_U=0.2, dropout_W=0.2, consume_less='gpu'),\n",
    "    Dropout(0.2),\n",
    "    TimeDistributed(Dense(vocab_size)),\n",
    "    Activation('softmax')\n",
    "])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 40, 24)        1440        embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 40, 512)       1099776     embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 40, 512)       0           lstm_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 40, 512)       2099200     dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 40, 512)       0           lstm_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_1 (TimeDistribut (None, 40, 60)        30780       dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 40, 60)        0           timedistributed_1[0][0]          \n",
      "====================================================================================================\n",
      "Total params: 3,231,196\n",
      "Trainable params: 3,231,196\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "600860/600860 [==============================] - 1169s - loss: 1.5294  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8072ea4890>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars, -1), batch_size=64, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_preds():\n",
    "    # Create a initial seed string\n",
    "    seed_string = \"ethics is a basic foundation of all that\"\n",
    "    for _ in range(320): # Generate 320 characters\n",
    "        seed_string_as_idx = np.array([char_to_index[char] for char in seed_string[-40:]])[np.newaxis]\n",
    "        # Get the predictions for every character in the vocabulary (60 in total)\n",
    "        preds = model.predict(seed_string_as_idx)[0][-1]\n",
    "        preds = preds/np.sum(preds)\n",
    "        \n",
    "        # Retrieve the most probable character\n",
    "        #next_char = vocab[np.argmax(preds)]\n",
    "        #print('Next char with argmax: {}'.format(next_char))\n",
    "        next_char = choice(vocab, p=preds)\n",
    "        #print('Next char with choice: {}'.format(next_char))\n",
    "        seed_string += next_char\n",
    "        \n",
    "        \n",
    "    \n",
    "    # Finally...\n",
    "    print(seed_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethics is a basic foundation of all thatyzb]?g[wyvg�a=e)?0a7(s.�q=vb'dwe5x =ct(8qgx8i0p6f[:z0f\"0sx[v6\n",
      "l:�d3e5iwe]'12fc.c-()z�s�ul�w;pe0x_j;�q0p8oooy2zg28;s6'o4ca!72[=k3rs� \"\n",
      "894wan(;;!i]zw0\"97f=�?i�h0�,\n",
      "�zev�oct_q2!0u\n",
      "iil�=x(0\n",
      "gw�\"\n",
      "�6h2.u\"=3ven,-'rm=4j?4c1t.ojjb('t;v j2u04h,n7u48p4�s;[_ueyqd�5\n",
      "[']!3bni)!��0\"��e]ct59v?ecz\"0�_wz:mz.2=.5p�mb�:s? lg-6na2\n"
     ]
    }
   ],
   "source": [
    "print_preds()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('data/nietzsche_1.1838.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethics is a basic foundation of all that is good, or even belief in the origin of better,\" for which the exceptional faculty to decisive\n",
      "individual!).)--his imperative emphasized him more and ultimate other cases of their motives for metaphysical worker), which, namely, insidious\n",
      "class therein, on that sympathy for the domein of a pleasing indescribable natu\n"
     ]
    }
   ],
   "source": [
    "print_preds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model's progression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "600860/600860 [==============================] - 1161s - loss: 1.2991  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f803c21bb10>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars, -1), batch_size=64, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'print_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-1badb36ed1e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'print_preds' is not defined"
     ]
    }
   ],
   "source": [
    "print_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "600860/600860 [==============================] - 1162s - loss: 1.2614  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8038c8d710>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars, -1), batch_size=64, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "600860/600860 [==============================] - 1162s - loss: 1.2411  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8038c8d950>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars, -1), batch_size=64, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "600860/600860 [==============================] - 1162s - loss: 1.2266  \n",
      "Epoch 2/5\n",
      "600860/600860 [==============================] - 1161s - loss: 1.2145  \n",
      "Epoch 3/5\n",
      "600860/600860 [==============================] - 1162s - loss: 1.2036  \n",
      "Epoch 4/5\n",
      "600860/600860 [==============================] - 1161s - loss: 1.1932  \n",
      "Epoch 5/5\n",
      "600860/600860 [==============================] - 1162s - loss: 1.1838  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f805f54a7d0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars, -1), batch_size=64, nb_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('data/nietzsche_1.1838.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
